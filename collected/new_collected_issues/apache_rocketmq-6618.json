{
  "issue_id": 6609,
  "issue_url": "https://github.com/apache/rocketmq/issues/6609",
  "title": "CQ building exceeds confirmOffset when node restarts to recover in ha mode",
  "description": "<p dir=\"auto\">The issue tracker is used for bug reporting purposes <strong>ONLY</strong> whereas feature request needs to follow the <a href=\"https://github.com/apache/rocketmq/wiki/RocketMQ-Improvement-Proposal\">RIP process</a>. To avoid unnecessary duplication, please check whether there is a previous issue before filing a new one.</p>\n<p dir=\"auto\">It is recommended to start a discussion thread in the <a href=\"http://rocketmq.apache.org/about/contact/\" rel=\"nofollow\">mailing lists</a> or <a href=\"https://github.com/apache/rocketmq/discussions\">github discussions</a> in cases of discussing your deployment plan, API clarification, and other non-bug-reporting issues.<br>\nWe welcome any friendly suggestions, bug fixes, collaboration, and other improvements.</p>\n<p dir=\"auto\">Please ensure that your bug report is clear and self-contained. Otherwise, it would take additional rounds of communication, thus more time, to understand the problem itself.</p>\n<p dir=\"auto\">Generally, fixing an issue goes through the following steps:</p>\n<ol dir=\"auto\">\n<li>Understand the issue reported;</li>\n<li>Reproduce the unexpected behavior locally;</li>\n<li>Perform root cause analysis to identify the underlying problem;</li>\n<li>Create test cases to cover the identified problem;</li>\n<li>Work out a solution to rectify the behavior and make the newly created test cases pass;</li>\n<li>Make a pull request and go through peer review;</li>\n</ol>\n<p dir=\"auto\">As a result, it would be very helpful yet challenging if you could provide an isolated project reproducing your reported issue. Anyway, please ensure your issue report is informative enough for the community to pick up. At a minimum, include the following hints:</p>\n<p dir=\"auto\"><strong>BUG REPORT</strong></p>\n<ol dir=\"auto\">\n<li>Please describe the issue you observed:<br>\nwe found this phenomenon in the following case :<br>\n[1] first, node1 as master, node2 as slave<br>\n[2] 2023-04-17 15:24:22, node1 is down, node2 will be elected as master<br>\n[3] 2023-04-17 15:24:23, node2 is down right after being elected as master<br>\n[4] 2023-04-17 15:26:03, node1 restarts<br>\n[5] 2023-04-17 15:46:05, node2 restarts<br>\n[6] 2023-04-17 15:46:20, node2 is elected as master and node1 is elected as slave.</li>\n</ol>\n<p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://user-images.githubusercontent.com/10379042/232707435-3bb1950d-8a54-4c34-bf27-684e6a0cf8e2.png\"><img src=\"https://user-images.githubusercontent.com/10379042/232707435-3bb1950d-8a54-4c34-bf27-684e6a0cf8e2.png\" alt=\"image\" style=\"max-width: 100%;\"></a></p>\n<p dir=\"auto\">we found that 4 messages was lost, those  4 messages was stored to node2's commitlog at 2023-04-17 15:46:42<br>\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://user-images.githubusercontent.com/10379042/232707614-ea2e3899-dae6-47e2-83a8-ac47c817d557.png\"><img src=\"https://user-images.githubusercontent.com/10379042/232707614-ea2e3899-dae6-47e2-83a8-ac47c817d557.png\" alt=\"image\" style=\"max-width: 100%;\"></a></p>\n<p dir=\"auto\">By checking the recovery log of node1, it is found that node1 builds cq with 4 dirty messages which will be truncate in the future.<br>\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://user-images.githubusercontent.com/10379042/232710514-d1f32589-c976-468d-9af1-50ffe92899ab.png\"><img src=\"https://user-images.githubusercontent.com/10379042/232710514-d1f32589-c976-468d-9af1-50ffe92899ab.png\" alt=\"image\" style=\"max-width: 100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://user-images.githubusercontent.com/10379042/232710444-6cc0d184-7d8e-4929-b4ed-8dbce88d6c43.png\"><img src=\"https://user-images.githubusercontent.com/10379042/232710444-6cc0d184-7d8e-4929-b4ed-8dbce88d6c43.png\" alt=\"image\" style=\"max-width: 100%;\"></a></p>\n<p dir=\"auto\">Also, broker has enabled reading messages from the slave. Client subscribes node1 at  2023-04-17 15:26:24 and consumes those<br>\n4 dirty messages, then commit the offset of these queue.</p>\n<p dir=\"auto\">After node2 is elected as master and node1 is elected to slave, those 4 dirty messages is truncate by node1, and another 4 new messages is appended to commitlog. However, the offset of these messages has already being commited.</p>\n<p dir=\"auto\">This also explains why messages are lost.</p>\n<ol start=\"2\" dir=\"auto\">\n<li>\n<p dir=\"auto\">Please tell us about your environment:</p>\n</li>\n<li>\n<p dir=\"auto\">Other information (e.g. detailed explanation, logs, related issues, suggestions on how to fix, etc):</p>\n</li>\n</ol>\n<p dir=\"auto\"><strong>FEATURE REQUEST</strong></p>\n<ol dir=\"auto\">\n<li>\n<p dir=\"auto\">Please describe the feature you are requesting.</p>\n</li>\n<li>\n<p dir=\"auto\">Provide any additional detail on your proposed use case for this feature.</p>\n</li>\n<li>\n<p dir=\"auto\">Indicate the importance of this issue to you (blocker, must-have, should-have, nice-to-have). Are you currently using any workarounds to address this issue?</p>\n</li>\n<li>\n<p dir=\"auto\">If there are some sub-tasks involved, use -[] for each sub-task and create a corresponding issue to map to the sub-task:</p>\n</li>\n</ol>\n<ul dir=\"auto\">\n<li><a href=\"example_sub_issue1_link_here\">sub-task1-issue-number</a>: sub-task1 description here,</li>\n<li><a href=\"example_sub_issue2_link_here\">sub-task2-issue-number</a>: sub-task2 description here,</li>\n<li>...</li>\n</ul>",
  "description_text": "The issue tracker is used for bug reporting purposes ONLY whereas feature request needs to follow the RIP process. To avoid unnecessary duplication, please check whether there is a previous issue before filing a new one.\nIt is recommended to start a discussion thread in the mailing lists or github discussions in cases of discussing your deployment plan, API clarification, and other non-bug-reporting issues.\nWe welcome any friendly suggestions, bug fixes, collaboration, and other improvements.\nPlease ensure that your bug report is clear and self-contained. Otherwise, it would take additional rounds of communication, thus more time, to understand the problem itself.\nGenerally, fixing an issue goes through the following steps:\n\nUnderstand the issue reported;\nReproduce the unexpected behavior locally;\nPerform root cause analysis to identify the underlying problem;\nCreate test cases to cover the identified problem;\nWork out a solution to rectify the behavior and make the newly created test cases pass;\nMake a pull request and go through peer review;\n\nAs a result, it would be very helpful yet challenging if you could provide an isolated project reproducing your reported issue. Anyway, please ensure your issue report is informative enough for the community to pick up. At a minimum, include the following hints:\nBUG REPORT\n\nPlease describe the issue you observed:\nwe found this phenomenon in the following case :\n[1] first, node1 as master, node2 as slave\n[2] 2023-04-17 15:24:22, node1 is down, node2 will be elected as master\n[3] 2023-04-17 15:24:23, node2 is down right after being elected as master\n[4] 2023-04-17 15:26:03, node1 restarts\n[5] 2023-04-17 15:46:05, node2 restarts\n[6] 2023-04-17 15:46:20, node2 is elected as master and node1 is elected as slave.\n\n\nwe found that 4 messages was lost, those  4 messages was stored to node2's commitlog at 2023-04-17 15:46:42\n\nBy checking the recovery log of node1, it is found that node1 builds cq with 4 dirty messages which will be truncate in the future.\n\n\nAlso, broker has enabled reading messages from the slave. Client subscribes node1 at  2023-04-17 15:26:24 and consumes those\n4 dirty messages, then commit the offset of these queue.\nAfter node2 is elected as master and node1 is elected to slave, those 4 dirty messages is truncate by node1, and another 4 new messages is appended to commitlog. However, the offset of these messages has already being commited.\nThis also explains why messages are lost.\n\n\nPlease tell us about your environment:\n\n\nOther information (e.g. detailed explanation, logs, related issues, suggestions on how to fix, etc):\n\n\nFEATURE REQUEST\n\n\nPlease describe the feature you are requesting.\n\n\nProvide any additional detail on your proposed use case for this feature.\n\n\nIndicate the importance of this issue to you (blocker, must-have, should-have, nice-to-have). Are you currently using any workarounds to address this issue?\n\n\nIf there are some sub-tasks involved, use -[] for each sub-task and create a corresponding issue to map to the sub-task:\n\n\n\nsub-task1-issue-number: sub-task1 description here,\nsub-task2-issue-number: sub-task2 description here,\n...\n"
}