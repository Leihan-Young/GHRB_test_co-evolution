{
  "issue_id": 6841,
  "issue_url": "https://github.com/apache/rocketmq/issues/6841",
  "title": "[Feature] pop batch ack for pushConsumer",
  "description": "<h3 dir=\"auto\">Is Your Feature Request Related to a Problem?</h3>\n<p dir=\"auto\">Currently, the POP consumer can pull up to 32 messages in batch, but after consuming one message, it needs to immediately ack once without achieving batching, which is inefficient and consumes bandwidth and CPU resources for both consumers and brokers.<br>\nTo address this issue, we propose a solution of POP batch ack.</p>\n<h3 dir=\"auto\">Describe the Solution You'd Like</h3>\n<p dir=\"auto\">The client consumption logic remains unchanged. When preparing to send an ACK request after successfully consuming a message, only cache the ACK in memory and the request to Broker is not actually made at this time.</p>\n<p dir=\"auto\">Meanwhile, when the number of cached ACKs exceeds <code class=\"notranslate\">MAX_COUNT_IN_BATCH</code>, or approaches the msg <code class=\"notranslate\">reviveTime</code>, or the memory retention time exceeds <code class=\"notranslate\">MAX_STAY_TIME_MS</code>, a service thread will request a batch ack to the corresponding broker.</p>\n<blockquote>\n<p dir=\"auto\">[consumerThread1] -----(ackInMem)----------\u2193<br>\n[consumerThread2]---(ackInMem)---> [BatchAckService] ---(batchAckAsync)--->  Broker<br>\n... ...<br>\n[consumerThreadn] -----(ackInMem)---------\u2191</p>\n</blockquote>\n<h3 dir=\"auto\">Describe Alternatives You've Considered</h3>\n<p dir=\"auto\">None.</p>\n<h3 dir=\"auto\">Additional Context</h3>\n<p dir=\"auto\">I will submit a pull request later.<br>\nThe submitted code has been thoroughly tested and has a large number of unit tests.<br>\nThis pop batch ack implementation can fully support the existing single ack and FIFO message ack.</p>",
  "description_text": "Is Your Feature Request Related to a Problem?\nCurrently, the POP consumer can pull up to 32 messages in batch, but after consuming one message, it needs to immediately ack once without achieving batching, which is inefficient and consumes bandwidth and CPU resources for both consumers and brokers.\nTo address this issue, we propose a solution of POP batch ack.\nDescribe the Solution You'd Like\nThe client consumption logic remains unchanged. When preparing to send an ACK request after successfully consuming a message, only cache the ACK in memory and the request to Broker is not actually made at this time.\nMeanwhile, when the number of cached ACKs exceeds MAX_COUNT_IN_BATCH, or approaches the msg reviveTime, or the memory retention time exceeds MAX_STAY_TIME_MS, a service thread will request a batch ack to the corresponding broker.\n\n[consumerThread1] -----(ackInMem)----------\u2193\n[consumerThread2]---(ackInMem)---> [BatchAckService] ---(batchAckAsync)--->  Broker\n... ...\n[consumerThreadn] -----(ackInMem)---------\u2191\n\nDescribe Alternatives You've Considered\nNone.\nAdditional Context\nI will submit a pull request later.\nThe submitted code has been thoroughly tested and has a large number of unit tests.\nThis pop batch ack implementation can fully support the existing single ack and FIFO message ack."
}